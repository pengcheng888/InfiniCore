import infinicore
import torch
import numpy as np


def test_matmul_basic():
    """æµ‹è¯•åŸºæœ¬çš„çŸ©é˜µä¹˜æ³•"""
    print("Testing basic matmul...")

    # åˆ›å»ºæµ‹è¯•æ•°æ®
    a_shape = [2, 3]
    b_shape = [3, 4]
    result_shape = [2, 4]

    # åˆ›å»ºPyTorchå¼ é‡ä½œä¸ºå‚è€ƒ
    torch_a = torch.rand(a_shape, dtype=torch.float32, device="cpu")
    torch_b = torch.rand(b_shape, dtype=torch.float32, device="cpu")
    torch_result = torch.matmul(torch_a, torch_b)

    # åˆ›å»ºinfinicoreå¼ é‡
    infini_a = infinicore.from_blob(
        torch_a.data_ptr(),
        a_shape,
        infinicore.float32,
        infinicore.device("cpu", 0),
    )

    infini_b = infinicore.from_blob(
        torch_b.data_ptr(),
        b_shape,
        infinicore.float32,
        infinicore.device("cpu", 0),
    )

    # æµ‹è¯•out-of-place matmul
    infini_result = infinicore.matmul(infini_a, infini_b)

    # éªŒè¯ç»“æœ
    torch_result_from_infini = torch.zeros(
        result_shape, dtype=torch.float32, device="cpu"
    )
    temp_tensor = infinicore.from_blob(
        torch_result_from_infini.data_ptr(),
        result_shape,
        infinicore.float32,
        infinicore.device("cpu", 0),
    )
    temp_tensor.copy_(infini_result)

    assert torch.allclose(
        torch_result, torch_result_from_infini, rtol=1e-5
    ), "Basic matmul test failed"
    print("âœ“ Basic matmul test passed")


def test_matmul_inplace():
    """æµ‹è¯•åŸåœ°çŸ©é˜µä¹˜æ³•"""
    print("Testing in-place matmul...")

    a_shape = [2, 3]
    b_shape = [3, 4]
    result_shape = [2, 4]

    torch_a = torch.rand(a_shape, dtype=torch.float32, device="cpu")
    torch_b = torch.rand(b_shape, dtype=torch.float32, device="cpu")
    torch_result = torch.matmul(torch_a, torch_b)

    # åˆ›å»ºé¢„åˆ†é…çš„ç»“æœå¼ é‡
    torch_preallocated = torch.zeros(result_shape, dtype=torch.float32, device="cpu")

    infini_a = infinicore.from_blob(
        torch_a.data_ptr(),
        a_shape,
        infinicore.float32,
        infinicore.device("cpu", 0),
    )

    infini_b = infinicore.from_blob(
        torch_b.data_ptr(),
        b_shape,
        infinicore.float32,
        infinicore.device("cpu", 0),
    )

    infini_c = infinicore.from_blob(
        torch_preallocated.data_ptr(),
        result_shape,
        infinicore.float32,
        infinicore.device("cpu", 0),
    )

    # æµ‹è¯•in-place matmul
    infinicore.matmul_(infini_c, infini_a, infini_b)

    assert torch.allclose(
        torch_result, torch_preallocated, rtol=1e-5
    ), "In-place matmul test failed"
    print("âœ“ In-place matmul test passed")


def test_matmul_gpu():
    """æµ‹è¯•GPUä¸Šçš„çŸ©é˜µä¹˜æ³•"""
    print("Testing GPU matmul...")

    if not torch.cuda.is_available():
        print("â­ï¸  GPU not available, skipping GPU test")
        return

    a_shape = [3, 4]
    b_shape = [4, 5]
    result_shape = [3, 5]

    # åˆ›å»ºCPUå¼ é‡
    torch_a_cpu = torch.rand(a_shape, dtype=torch.float32, device="cuda")
    torch_b_cpu = torch.rand(b_shape, dtype=torch.float32, device="cuda")
    torch_result = torch.matmul(torch_a_cpu, torch_b_cpu)

    # è½¬ç§»åˆ°GPU
    torch_a_gpu = torch_a_cpu.cuda()
    torch_b_gpu = torch_b_cpu.cuda()

    # åˆ›å»ºinfinicore GPUå¼ é‡
    infini_a_gpu = infinicore.from_blob(
        torch_a_gpu.data_ptr(),
        a_shape,
        infinicore.float32,
        infinicore.device("cuda", 0),
    )

    infini_b_gpu = infinicore.from_blob(
        torch_b_gpu.data_ptr(),
        b_shape,
        infinicore.float32,
        infinicore.device("cuda", 0),
    )

    # åœ¨GPUä¸Šæ‰§è¡Œmatmul
    infini_result = infinicore.matmul(infini_a_gpu, infini_b_gpu)

    # å°†ç»“æœè½¬ç§»å›CPUéªŒè¯
    infini_result = infinicore.matmul(infini_a_gpu, infini_b_gpu)

    torch_result_from_infini = torch.zeros(
        result_shape, dtype=torch.float32, device="cuda"
    )
    temp_tensor = infinicore.from_blob(
        torch_result_from_infini.data_ptr(),
        result_shape,
        infinicore.float32,
        infinicore.device("cuda", 0),
    )
    temp_tensor.copy_(infini_result)

    assert torch.allclose(
        torch_result, torch_result_from_infini, rtol=1e-5
    ), "GPU matmul test failed"
    print("âœ“ GPU matmul test passed")


def test_matmul_batch():
    """æµ‹è¯•æ‰¹é‡çŸ©é˜µä¹˜æ³•"""
    print("Testing batch matmul...")

    batch_size = 2
    a_shape = [batch_size, 3, 4]
    b_shape = [batch_size, 4, 5]
    result_shape = [batch_size, 3, 5]

    torch_a = torch.rand(a_shape, dtype=torch.float32, device="cpu")
    torch_b = torch.rand(b_shape, dtype=torch.float32, device="cpu")
    torch_result = torch.bmm(torch_a, torch_b)  # æ‰¹é‡çŸ©é˜µä¹˜æ³•

    infini_a = infinicore.from_blob(
        torch_a.data_ptr(),
        a_shape,
        infinicore.float32,
        infinicore.device("cpu", 0),
    )

    infini_b = infinicore.from_blob(
        torch_b.data_ptr(),
        b_shape,
        infinicore.float32,
        infinicore.device("cpu", 0),
    )

    infini_result = infinicore.matmul(infini_a, infini_b)

    torch_result_from_infini = torch.zeros(
        result_shape, dtype=torch.float32, device="cpu"
    )
    temp_tensor = infinicore.from_blob(
        torch_result_from_infini.data_ptr(),
        result_shape,
        infinicore.float32,
        infinicore.device("cpu", 0),
    )
    temp_tensor.copy_(infini_result)

    assert torch.allclose(
        torch_result, torch_result_from_infini, rtol=1e-5
    ), "Batch matmul test failed"
    print("âœ“ Batch matmul test passed")


def test_matmul_large():
    """æµ‹è¯•å¤§çŸ©é˜µä¹˜æ³•"""
    print("Testing large matmul...")

    a_shape = [128, 256]
    b_shape = [256, 64]
    result_shape = [128, 64]

    torch_a = torch.rand(a_shape, dtype=torch.float32, device="cpu")
    torch_b = torch.rand(b_shape, dtype=torch.float32, device="cpu")
    torch_result = torch.matmul(torch_a, torch_b)

    infini_a = infinicore.from_blob(
        torch_a.data_ptr(),
        a_shape,
        infinicore.float32,
        infinicore.device("cpu", 0),
    )

    infini_b = infinicore.from_blob(
        torch_b.data_ptr(),
        b_shape,
        infinicore.float32,
        infinicore.device("cpu", 0),
    )

    infini_result = infinicore.matmul(infini_a, infini_b)

    torch_result_from_infini = torch.zeros(
        result_shape, dtype=torch.float32, device="cpu"
    )
    temp_tensor = infinicore.from_blob(
        torch_result_from_infini.data_ptr(),
        result_shape,
        infinicore.float32,
        infinicore.device("cpu", 0),
    )
    temp_tensor.copy_(infini_result)

    assert torch.allclose(
        torch_result, torch_result_from_infini, rtol=1e-5
    ), "Large matmul test failed"
    print("âœ“ Large matmul test passed")


def run_all_tests():
    """è¿è¡Œæ‰€æœ‰æµ‹è¯•"""
    print("Starting matmul tests...\n")

    try:
        test_matmul_basic()
        test_matmul_inplace()
        test_matmul_batch()
        test_matmul_large()
        test_matmul_gpu()

        print("\nğŸ‰ All matmul tests passed!")

    except Exception as e:
        print(f"\nâŒ Test failed with error: {e}")
        raise


if __name__ == "__main__":
    run_all_tests()
